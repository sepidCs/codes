{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _*_ coding:utf-8 _*_\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "import scipy.stats\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "plt.rcParams['font.sans-serif']=['SimHei'] # Used to properly display Chinese labels\n",
    "plt.rcParams['axes.unicode_minus']=False # Used to properly display negative signs\n",
    "\n",
    "# Normalize data\n",
    "def autos(X):\n",
    "    m = X.shape[0]\n",
    "    n = X.shape[1]\n",
    "    X_m = np.zeros((m, n))\n",
    "    mu = np.mean(X, axis=0)\n",
    "    sigma = np.std(X, axis=0, ddof=1)\n",
    "    for i in range(n):\n",
    "        a = np.ones(m) * mu[i]\n",
    "        X_m[:, i] = (X[:, i]-a) / sigma[i]\n",
    "    return X_m, mu, sigma\n",
    "\n",
    "def autos_test(data,m_train,v_train):\n",
    "    m = data.shape[0]\n",
    "    n = data.shape[1]\n",
    "    data_new = np.zeros((m, n))\n",
    "    for i in range(n):\n",
    "        a = np.ones(m) * m_train[i]\n",
    "        data_new[:, i] = (data[:, i] - a) / v_train[i]\n",
    "    return data_new\n",
    "#hamoon pca energy hast\n",
    "def pc_number(X):\n",
    "    U, S, V = np.linalg.svd(X)\n",
    "    if S.shape[0] == 1:\n",
    "        i = 1\n",
    "    else:\n",
    "        i = 0\n",
    "        var = 0\n",
    "        while var < 0.85*sum(S*S):\n",
    "            var = var+S[i]*S[i]\n",
    "            i = i + 1\n",
    "    return i\n",
    "\n",
    "def DiPCA(X, s, a):\n",
    "    n = X.shape[0]\n",
    "    m = X.shape[1]\n",
    "    N = n - s\n",
    "    Xe = X[s:N+s, :]\n",
    "    alpha = 0.01\n",
    "    level = 1-alpha\n",
    "    P = np.zeros((m, a))\n",
    "    W = np.zeros((m, a))\n",
    "    T = np.zeros((n, a))\n",
    "    w = np.ones(m)\n",
    "    w = w / np.linalg.norm(w, ord=2)\n",
    "\n",
    "    if s > 0:\n",
    "        l = 0\n",
    "        while l < a:\n",
    "            iterr = 1000\n",
    "            temp = np.dot(X, w)\n",
    "            while iterr > 0.00001:\n",
    "                t = np.dot(X, w)\n",
    "                beta = np.ones((s))\n",
    "                for i in range(s):\n",
    "                    beta[i] = np.dot(t[i:N+i-1].T, t[s:N+s-1])\n",
    "                beta = beta / np.linalg.norm(beta, ord=2)\n",
    "                w = np.zeros(m)\n",
    "\n",
    "                for i in range(s):\n",
    "                    w = w + beta[i]*(np.dot(X[s:N+s-1, :].T, t[i:N+i-1]) +\n",
    "                                     np.dot(X[i:N+i-1].T, t[s:N+s-1]))\n",
    "                w = w / np.linalg.norm(w, ord=2)\n",
    "                t = np.dot(X, w)\n",
    "                iterr = np.linalg.norm((t-temp), ord=2)\n",
    "\n",
    "                temp = t\n",
    "            p = np.dot(X.T, t)/np.dot(t.T, t)\n",
    "            p = X.T@ t/(t.T@t)\n",
    "\n",
    "            t = np.array([t]).T\n",
    "\n",
    "            p = np.array([p]).T\n",
    "            X = X - np.dot(t, p.T)\n",
    "            P[:, l] = p[:, 0]\n",
    "            W[:, l] = w\n",
    "            T[:, l] = t[:, 0]\n",
    "            l = l+1\n",
    "\n",
    "        # Dynamic Inner Modeling\n",
    "        TT = T[0:N, :]\n",
    "        j = 1\n",
    "        while j < s:\n",
    "            TT = np.c_[TT, T[j:(N+j), :]]\n",
    "            j = j+1\n",
    "        Theta = np.dot(np.dot(np.linalg.inv(np.dot(TT.T, TT)), TT.T), T[s:N+s, :])\n",
    "\n",
    "        V = T[s:N+s, :] - np.dot(TT, Theta)\n",
    "        a_v = pc_number(V)\n",
    "\n",
    "        _, Sv, Pv = np.linalg.svd(V)\n",
    "        Pv = Pv.T\n",
    "        Pv = Pv[:, 0:a_v]\n",
    "        lambda_v = 1/(N-1)*np.diag(Sv[0:a_v]**2)\n",
    "        if a_v!=a: # Ensure both T^2 and Q exist\n",
    "            gv = 1/(N-1)*sum(Sv[a_v:a]**4)/sum(Sv[a_v:a]**2)\n",
    "            hv = (sum(Sv[a_v:a]**2)**2)/sum(Sv[a_v:a]**4)\n",
    "            Tv2_lim = a_v * (N ** 2 - 1) / (N * (N - a_v))* scipy.stats.f.ppf(level, a_v, N-a_v)\n",
    "            Qv_lim = gv*scipy.stats.chi2.ppf(level, hv)\n",
    "            PHI_v = np.dot(np.dot(Pv, np.linalg.inv(lambda_v)), Pv.T)/Tv2_lim + (np.identity(len(Pv@Pv.T))-Pv@Pv.T)/Qv_lim;\n",
    "            SS_v=1/(N-1)*V.T@V\n",
    "            g_phi_v=np.trace((SS_v@PHI_v)@(SS_v@PHI_v))/(np.trace(SS_v@PHI_v))\n",
    "            h_phi_v=(np.trace(SS_v@SS_v)**2)/np.trace((SS_v@PHI_v)@(SS_v@PHI_v))\n",
    "            phi_v_lim = g_phi_v*scipy.stats.chi2.ppf(level, h_phi_v)\n",
    "        else:\n",
    "            Tv2_lim = a_v * (N ** 2 - 1) / (N * (N - a_v))* scipy.stats.f.ppf(level, a_v, N-a_v)\n",
    "            PHI_v = np.dot(np.dot(Pv, np.linalg.inv(lambda_v)), Pv.T)\n",
    "            phi_v_lim=Tv2_lim\n",
    "        Xe = Xe-np.dot(np.dot(TT, Theta), P.T)\n",
    "    a_s = pc_number(Xe)\n",
    "    _, Ss, Ps = np.linalg.svd(Xe)\n",
    "    Ps = Ps.T\n",
    "    Ps = Ps[:,0:a_s]\n",
    "    Ts = np.dot(Xe, Ps)\n",
    "    lambda_s = 1 / (N - 1) * np.diag(Ss[0:a_s] ** 2)\n",
    "    m = Ss.shape[0]\n",
    "    gs = 1 / (N - 1) * sum(Ss[a_s:m] ** 4) / sum(Ss[a_s:m] ** 2)\n",
    "    hs = (sum(Ss[a_s:m] ** 2) ** 2) / sum(Ss[a_s:m] ** 4)\n",
    "\n",
    "    Ts2_lim = scipy.stats.chi2.ppf(level,a_s)\n",
    "    Qs_lim = gs*scipy.stats.chi2.ppf(level,hs)\n",
    "    print(P.shape,W.shape,Ps.shape,Theta.shape)\n",
    "    # print( P,W,Theta,Ps,lambda_s,PHI_v,phi_v_lim,Ts2_lim ,Qs_lim)\n",
    "    return P,W,Theta,Ps,lambda_s,PHI_v,phi_v_lim,Ts2_lim ,Qs_lim\n",
    "\n",
    "def DiPCA_test(X,P,W,Theta,Ps,s,lambda_s,PHI_v):\n",
    "    \"\"\"\n",
    "    DiPCA testing for monitoring\n",
    "    \"\"\"\n",
    "    n = X.shape[0]\n",
    "    N = n - s\n",
    "    a = P.shape[1]\n",
    "    Mst = np.dot(np.dot(Ps, np.linalg.inv(lambda_s)), Ps.T)\n",
    "    Msq = np.eye((Mst.shape[0])) - np.dot(Ps, Ps.T)\n",
    "    R = np.dot(W, np.linalg.inv(np.dot(P.T, W)))\n",
    "    if s > 0:\n",
    "        T = np.dot(X, R)\n",
    "        TTs = T[s:N+s, :]\n",
    "        Ts = np.zeros((N, s))\n",
    "        TT = T[0:N, :]\n",
    "        i = 1\n",
    "        while i < s:\n",
    "            Ts = T[i:N+i, :]\n",
    "            TT = np.c_[TT, Ts]\n",
    "            i = i + 1\n",
    "        TTshat = np.dot(TT, Theta)\n",
    "\n",
    "    phi_v_index = np.zeros(N)\n",
    "    Ts_index = np.zeros(N)\n",
    "    Qs_index = np.zeros(N)\n",
    "    k = s\n",
    "    while k < s+N:\n",
    "        if s > 0:\n",
    "            temp = TTs[k-s, :] - TTshat[k-s, :]\n",
    "            temp = np.array([temp])\n",
    "            v = temp.T\n",
    "            phi_v_index[k-s] = np.dot(np.dot(v.T, PHI_v), v)\n",
    "            e = X[k-s, :].T - np.dot(P, TTshat[k-s, :].T)\n",
    "        else:\n",
    "            e = X[k-s, :].T\n",
    "        Ts_index[k-s] = np.dot(np.dot(e.T, Mst), e)\n",
    "        Qs_index[k-s] = np.dot(np.dot(e.T, Msq), e)\n",
    "        k = k+1\n",
    "\n",
    "    return phi_v_index,Ts_index,Qs_index\n",
    "\n",
    "\n",
    "def DiPCA_predict(X,P,W,Theta,s):\n",
    "    \"\"\"\n",
    "    DiPCA prediction\n",
    "    \"\"\"\n",
    "    n = X.shape[0]\n",
    "    N = n - s\n",
    "    a = P.shape[1]\n",
    "    x_predict_d=np.zeros(X.shape, dtype=float)\n",
    "\n",
    "    R = np.dot(W, np.linalg.inv(np.dot(P.T, W)))\n",
    "    if s > 0:\n",
    "        T = np.dot(X, R)\n",
    "        TT = T[0:N, :]\n",
    "        i = 1\n",
    "        while i < s:\n",
    "            Ts = T[i:N+i, :]\n",
    "            TT = np.c_[TT, Ts]\n",
    "            i = i + 1\n",
    "        TTshat = np.dot(TT, Theta)\n",
    "        x_predict_d[s:,:] =TTshat@P.T\n",
    "    return x_predict_d\n",
    "\n",
    "\n",
    "\n",
    "def DiPCA_cv(X,s_range,a_range,fold):\n",
    "    \"\"\"\n",
    "    DiPCA cross-validation to select the number of principal components\n",
    "    Input: X (training data), s_range (maximum value for selecting the lag order), \n",
    "    a_range (maximum value for selecting the latent variables), fold (number of folds for cross-validation)\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=fold,shuffle=False) #,random_state=1\n",
    "    press=np.zeros((s_range,a_range,fold), float)\n",
    "    for i in range(s_range):\n",
    "        for j in range(a_range):\n",
    "            count=0\n",
    "            for train_index, valid_index in kf.split(X):\n",
    "                count+=1\n",
    "                X_train, X_valid = X[train_index], X[valid_index]\n",
    "                P,W,Theta,Ps,lambda_s,PHI_v,phi_v_lim,Ts2_lim ,Qs_lim = DiPCA(X_train, i+1, j+1);# Modeling\n",
    "                X_predict=DiPCA_predict(X_valid,P,W,Theta, i+1)# Prediction\n",
    "                press[i][j][count-1]=np.linalg.norm(X_valid-X_predict,ord=2)**2/X_valid.shape[0]\n",
    "    press=np.sum(press, axis=2)\n",
    "    (s,a)=np.where(press==np.min(press))# Select the minimum PRESS value as s and a\n",
    "    s+=1\n",
    "    a+=1\n",
    "    return int(s),int(a)\n",
    "\n",
    "\"\"\"\n",
    "    DiPCA visualization\n",
    "    Currently, there are three main monitoring indicators, including the dynamic comprehensive indicator, \n",
    "    static T2 indicator, and static indicator\n",
    "    Parameters\n",
    "    ----------\n",
    "\"\"\"\n",
    "def DiPCA_visualization(phi_v_index,Ts_index,Qs_index,phi_v_lim,Ts2_lim,Qs_lim):\n",
    "    plt.figure(figsize=(9.6,6.4),dpi=600)\n",
    "    ax1 = plt.subplot(3,1,1)\n",
    "    ax1.plot(phi_v_index)\n",
    "    ax1.plot(phi_v_lim*np.ones(len(phi_v_index)),'r--')\n",
    "    ax1.set_xlabel('Samples')\n",
    "    ax1.set_ylabel('$\\phi_v$')\n",
    "    ax1.set_title('monitor')\n",
    "    ax2 = plt.subplot(3,1,2)\n",
    "    ax2.plot(Ts_index)\n",
    "    ax2.plot(Ts2_lim*np.ones(len(phi_v_index)),'r--')\n",
    "    ax2.set_xlabel('Samples')\n",
    "    ax2.set_ylabel('$T^2_s$')\n",
    "    ax3 = plt.subplot(3,1,3)\n",
    "    ax3.plot(Qs_index)\n",
    "    ax3.plot(Qs_lim*np.ones(len(phi_v_index)),'r--')\n",
    "    ax3.set_xlabel('Samples')\n",
    "    ax3.set_ylabel('$Q_s$')\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autos(X):\n",
    "    m = X.shape[0]\n",
    "    n = X.shape[1]\n",
    "    X_m = np.zeros((m, n))\n",
    "    mu = np.mean(X, axis=0)\n",
    "    sigma = np.std(X, axis=0, ddof=1)\n",
    "    for i in range(n):\n",
    "        a = np.ones(m) * mu[i]\n",
    "        X_m[:, i] = (X[:, i]-a) / sigma[i]\n",
    "    return X_m, mu, sigma\n",
    "\n",
    "def DiPCA(X, s, a):\n",
    "    n = X.shape[0]\n",
    "    m = X.shape[1]\n",
    "    N = n - s\n",
    "    Xe = X[s:N+s, :]\n",
    "    alpha = 0.01\n",
    "    level = 1 - alpha\n",
    "    P = np.zeros((m, a))\n",
    "    W = np.zeros((m, a))\n",
    "    T = np.zeros((n, a))\n",
    "    w = np.ones(m)\n",
    "    w = w / np.linalg.norm(w, ord=2)\n",
    "\n",
    "    l = 0\n",
    "    while l < a:\n",
    "        iterr = 1000\n",
    "        temp = np.dot(X, w)\n",
    "        while iterr > 0.00001:\n",
    "            t = np.dot(X, w)\n",
    "            beta = np.ones((s))\n",
    "            for i in range(s):\n",
    "                beta[i] = np.dot(t[i:N+i-1].T, t[s:N+s-1])\n",
    "            beta = beta / np.linalg.norm(beta, ord=2)\n",
    "            w = np.zeros(m)\n",
    "\n",
    "            for i in range(s):\n",
    "                w = w + beta[i] * (np.dot(X[s:N+s-1, :].T, t[i:N+i-1]) +\n",
    "                                   np.dot(X[i:N+i-1].T, t[s:N+s-1]))\n",
    "            w = w / np.linalg.norm(w, ord=2)\n",
    "            t = np.dot(X, w)\n",
    "            iterr = np.linalg.norm((t - temp), ord=2)\n",
    "\n",
    "            temp = t\n",
    "        p = np.dot(X.T, t) / np.dot(t.T, t)\n",
    "        p = X.T @ t / (t.T @ t)\n",
    "\n",
    "        t = np.array([t]).T\n",
    "        p = np.array([p]).T\n",
    "        X = X - np.dot(t, p.T)\n",
    "        P[:, l] = p[:, 0]\n",
    "        W[:, l] = w\n",
    "        T[:, l] = t[:, 0]\n",
    "        l = l + 1\n",
    "\n",
    "    # Dynamic Inner Modeling\n",
    "    TT = T[0:N, :]\n",
    "    j = 1\n",
    "    while j < s:\n",
    "        TT = np.c_[TT, T[j:(N+j), :]]\n",
    "        j = j + 1\n",
    "    Theta = np.dot(np.dot(np.linalg.inv(np.dot(TT.T, TT)), TT.T), T[s:N+s, :])\n",
    "\n",
    "    V = T[s:N+s, :] - np.dot(TT, Theta)\n",
    "    # #\n",
    "    # epsilon = 1e-10  # Small regularization constant\n",
    "    # V += epsilon * np.eye(V.shape[0])\n",
    "    # #\n",
    "    # Always return 'a' components\n",
    "    _, Sv, Pv = np.linalg.svd(V)\n",
    "    Pv = Pv.T\n",
    "    Pv = Pv[:, 0:a]\n",
    "    lambda_v = 1 / (N - 1) * np.diag(Sv[0:a] ** 2)\n",
    "\n",
    "    if a != a:\n",
    "        gv = 1 / (N - 1) * sum(Sv[a:a] ** 4) / sum(Sv[a:a] ** 2)\n",
    "        hv = (sum(Sv[a:a] ** 2) ** 2) / sum(Sv[a:a] ** 4)\n",
    "        Tv2_lim = a * (N ** 2 - 1) / (N * (N - a)) * scipy.stats.f.ppf(level, a, N - a)\n",
    "        Qv_lim = gv * scipy.stats.chi2.ppf(level, hv)\n",
    "        PHI_v = np.dot(np.dot(Pv, np.linalg.inv(lambda_v)), Pv.T) / Tv2_lim + (np.identity(len(Pv @ Pv.T)) - Pv @ Pv.T) / Qv_lim\n",
    "        SS_v = 1 / (N - 1) * V.T @ V\n",
    "        g_phi_v = np.trace((SS_v @ PHI_v) @ (SS_v @ PHI_v)) / (np.trace(SS_v @ PHI_v))\n",
    "        h_phi_v = (np.trace(SS_v @ SS_v) ** 2) / np.trace((SS_v @ PHI_v) @ (SS_v @ PHI_v))\n",
    "        phi_v_lim = g_phi_v * scipy.stats.chi2.ppf(level, h_phi_v)\n",
    "    else:\n",
    "        Tv2_lim = a * (N ** 2 - 1) / (N * (N - a)) * scipy.stats.f.ppf(level, a, N - a)\n",
    "        PHI_v = np.dot(np.dot(Pv, np.linalg.inv(lambda_v)), Pv.T)\n",
    "        phi_v_lim = Tv2_lim\n",
    "\n",
    "    Xe = Xe - np.dot(np.dot(TT, Theta), P.T)\n",
    "\n",
    "    # Fixed number of components in the second SVD\n",
    "    _, Ss, Ps = np.linalg.svd(Xe)\n",
    "    Ps = Ps.T\n",
    "    Ps = Ps[:, 0:a]\n",
    "    Ts = np.dot(Xe, Ps)\n",
    "    lambda_s = 1 / (N - 1) * np.diag(Ss[0:a] ** 2)\n",
    "    m = Ss.shape[0]\n",
    "    gs = 1 / (N - 1) * sum(Ss[a:m] ** 4) / sum(Ss[a:m] ** 2)\n",
    "    hs = (sum(Ss[a:m] ** 2) ** 2) / sum(Ss[a:m] ** 4)\n",
    "\n",
    "    Ts2_lim = scipy.stats.chi2.ppf(level, a)\n",
    "    Qs_lim = gs * scipy.stats.chi2.ppf(level, hs)\n",
    "\n",
    "    return P, W, Theta, Ps, lambda_s, PHI_v, phi_v_lim, Ts2_lim, Qs_lim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension Reduced Factors (Ps) Shape: (5, 3)\n",
      "Dimension Reduced Factors (Ps): [[ 0.54762234  0.07592202 -0.64032975]\n",
      " [ 0.3922168  -0.632427   -0.12521196]\n",
      " [ 0.45666567 -0.30202058  0.70025476]\n",
      " [ 0.54404449  0.41776285  0.0392122 ]\n",
      " [ 0.20432282  0.57317511  0.2870635 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example data matrix X with shape (500, 52)\n",
    "np.random.seed(0)\n",
    "X = np.random.rand(10, 5)\n",
    "X, X_mean, X_s = autos(X)\n",
    "# Define parameters\n",
    "s = 2  # Example value, adjust based on your needs\n",
    "a = 3  # Number of components\n",
    "\n",
    "# Call the DiPCA function\n",
    "P, W, Theta, Ps, lambda_s, PHI_v, phi_v_lim, Ts2_lim, Qs_lim = DiPCA(X, s, a)\n",
    "\n",
    "# The matrix Ps now contains the dimension-reduced factors\n",
    "print(\"Dimension Reduced Factors (Ps) Shape:\", Ps.shape)\n",
    "print(\"Dimension Reduced Factors (Ps):\", Ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components (a): 13\n",
      "P Shape: (5, 3)\n",
      "W Shape: (5, 3)\n",
      "Theta Shape: (6, 3)\n",
      "Ps Shape: (5, 3)\n"
     ]
    }
   ],
   "source": [
    "# Check if `a` is set correctly\n",
    "print(\"Number of components (a):\", a)\n",
    "\n",
    "# Debugging the function outputs\n",
    "print(\"P Shape:\", P.shape)\n",
    "print(\"W Shape:\", W.shape)\n",
    "print(\"Theta Shape:\", Theta.shape)\n",
    "print(\"Ps Shape:\", Ps.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
