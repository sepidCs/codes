{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import tucker\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "import xgboost as xg\n",
    "from scipy.fft import dct\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "sys.path.insert(1,'D:\\TMU_codes\\Thesis_codes\\codes')\n",
    "# for line in sys.path:\n",
    "#      print (line)\n",
    "# from package.featureSelection_SICE import *\n",
    "from package.loadDb import *\n",
    "from package.featureSelection_TEMPORAL_PAGERANK import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data with target size =  (2000, 11)\n"
     ]
    }
   ],
   "source": [
    "# import kaggle dataset\n",
    "address = \"..\\database\\kaggleDataFrame\"\n",
    "\n",
    "data_with_target= load_kaggle_dataframe(address+\"\\dataframes.csv\")\n",
    "\n",
    "data_with_target=data_with_target.iloc[:2000]\n",
    "\n",
    "data_without_target = data_with_target.drop(['DEMAND'],axis=1)\n",
    "\n",
    "print(\"data with target size = \",data_with_target.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimum_window_size_tpr(datacut,win_list,validation_size,num_comp):\n",
    "# datacut= data without validation samples\n",
    "    n_rows,n_features=datacut.shape\n",
    "    mse_per_win_dict={}\n",
    "    for window_size in win_list:\n",
    "\n",
    "        #input of xgboost\n",
    "        X_datacut=datacut.iloc[:,:-1]\n",
    "        Y_datacut=datacut.iloc[:,-1]\n",
    "\n",
    "        #input of feature selection\n",
    "        X_datacut_train=X_datacut.iloc[:n_rows-validation_size,:]\n",
    "        print('optimum_window train',X_datacut_train.shape)\n",
    "        # we apply feature selection on train set\n",
    "        arr=create_graph_details(X_datacut_train,window_size)\n",
    "        a=featureSelection_tpr(arr,n_features,num_comp)\n",
    "\n",
    "        mse=xgboost_reg_error(X_datacut[X_datacut.columns[a][0]].values,Y_datacut,validation_size)\n",
    "        mse_per_win_dict[window_size]=mse\n",
    "    optimum_widowSize=min(mse_per_win_dict, key=mse_per_win_dict.get)\n",
    "    return optimum_widowSize,mse_per_win_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_without_target=data_with_target.iloc[:,:-1]\n",
    "num_features=data_with_target.shape[1]\n",
    "\n",
    "num_comp=4\n",
    "# window_size=10\n",
    "interval = 2000\n",
    "test_size=200\n",
    "win_list=[2,3,4,5,6,7,10,30]\n",
    "validation_size=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compute_pca' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [5], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m Y_datacut\u001b[39m=\u001b[39mdatacut\u001b[39m.\u001b[39miloc[:,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m     11\u001b[0m \u001b[39m# print(counter,X_datacut.shape)\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m X_pca\u001b[39m=\u001b[39mcompute_pca(X_datacut,num_comp\u001b[39m=\u001b[39mnum_comp)\n\u001b[0;32m     14\u001b[0m pca_mse\u001b[39m=\u001b[39mxgboost_reg_error(X_pca,Y_datacut,test_size)\n\u001b[0;32m     15\u001b[0m pca_list\u001b[39m.\u001b[39mappend(pca_mse)\u001b[39m##########################\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'compute_pca' is not defined"
     ]
    }
   ],
   "source": [
    "counter=0\n",
    "pca_list=[]\n",
    "dict_mse={}\n",
    "\n",
    "while counter+interval <= data_without_target.shape[0]:\n",
    "\n",
    "\n",
    "    datacut=data_with_target[counter:counter+interval]\n",
    "    X_datacut=datacut.iloc[:,:-1]\n",
    "    Y_datacut=datacut.iloc[:,-1]\n",
    "    # print(counter,X_datacut.shape)\n",
    "    X_pca=compute_pca(X_datacut,num_comp=num_comp)\n",
    "\n",
    "    pca_mse=xgboost_reg_error(X_pca,Y_datacut,test_size)\n",
    "    pca_list.append(pca_mse)##########################\n",
    "    counter+=interval\n",
    "dict_mse['PCA']=pca_list\n",
    "\n",
    "    \n",
    "\n",
    "method_list = []\n",
    "counter=0\n",
    "\n",
    "while counter+interval <= data_without_target.shape[0]:\n",
    "    \n",
    "    n_rows,n_features=datacut.shape\n",
    "\n",
    "    datacut=data_with_target[counter:counter+interval]\n",
    "\n",
    "    X_datacut=datacut.iloc[:,:-1]\n",
    "    Y_datacut=datacut.iloc[:,-1]\n",
    "    window_size,_=optimum_window_size_tpr(datacut.iloc[:n_rows-test_size],win_list,validation_size,num_comp)\n",
    "    print(\"train\",X_datacut.iloc[:n_rows-test_size].shape)\n",
    "    arr=create_graph_details(X_datacut,window_size)\n",
    "    a=featureSelection_tpr(arr,X_datacut.shape[1],num_comp)\n",
    "    mse=xgboost_reg_error(X_datacut[X_datacut.columns[a][0]].values,Y_datacut,test_size)\n",
    "\n",
    "    method_list.append(mse)\n",
    "    #     print( \"method_list\",method_list)\n",
    "    print(counter/interval)\n",
    "    print(\"----------------------------------------------------------------------------\")\n",
    "    counter+=interval\n",
    "# dict_mse[\"T-PR win={}\".format(window_size)]=method_list\n",
    "dict_mse[\"fs_temporal pr\"]=method_list\n",
    "\n",
    "dataframe = pd.DataFrame(dict_mse)\n",
    "plt.rcParams[\"figure.figsize\"] = [11,7]\n",
    "dataframe.plot(kind=\"box\",title=\"num_comp={}\".format(num_comp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.plot(kind='line', marker='*', ylabel='RMSE',xlabel=\"dataframe number\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [6], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m x_train\u001b[39m=\u001b[39mx_train\u001b[39m.\u001b[39mreshape(x_train\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m],\u001b[39m1\u001b[39m,x_train\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m])\n\u001b[0;32m      5\u001b[0m \u001b[39m# create and fit the LSTM network\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m model \u001b[39m=\u001b[39m Sequential()\n\u001b[0;32m      7\u001b[0m model\u001b[39m.\u001b[39madd(LSTM(\u001b[39m4\u001b[39m, input_shape\u001b[39m=\u001b[39m( \u001b[39m1\u001b[39m, \u001b[39m10\u001b[39m)))\n\u001b[0;32m      8\u001b[0m model\u001b[39m.\u001b[39madd(Dense(\u001b[39m1\u001b[39m,activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msigmoid\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_without_target, data_without_target.iloc[:,-1], test_size = 500,shuffle=False)\n",
    "x_train=x_train.to_numpy()\n",
    "x_train=x_train.reshape(x_train.shape[0],1,x_train.shape[1])\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=( 1, 10)))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(x_train, y_train, epochs=100, batch_size=1)\n",
    "x_test=x_test.to_numpy()\n",
    "x_test=x_test.reshape(x_test.shape[0],1,x_test.shape[1])\n",
    "\n",
    "yhat = model.predict(x_test)\n",
    "rmse=np.sqrt(metrics.mean_squared_error(y_test, yhat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "x_test=x_test.to_numpy()\n",
    "x_test=x_test.reshape(x_test.shape[0],1,x_test.shape[1])\n",
    "\n",
    "yhat = model.predict(x_test)\n",
    "rmse=np.sqrt(metrics.mean_squared_error(y_test, yhat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.205946120274056"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eb9bb2fa3c6d437e42749e79e4a1d55d8d222e6cc8216a87b1a35470410f9d89"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
